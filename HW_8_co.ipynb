{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(pred, y):\n",
    "    return np.sum((pred != y).astype(int)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(X, y, N):\n",
    "\n",
    "    n_objects = len(X)\n",
    "\n",
    "    n_classes = len(np.unique((y)))\n",
    "\n",
    "    w = np.ones(n_objects) / n_objects\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for n in range(N):\n",
    "        clf = DecisionTreeClassifier(max_depth=1)\n",
    "        clf.fit(X, y, w)\n",
    "\n",
    "        predictions = clf.predict(X)\n",
    "        e = get_error(predictions, y)\n",
    "        if e >= 1 - 1/n_classes: \n",
    "            break\n",
    "\n",
    "        alpha = 0.5 * np.log((1 - e) / e)\n",
    "\n",
    "        match = predictions == y\n",
    "\n",
    "        w[np.logical_not(match)] *= np.exp(alpha)\n",
    "        w[match] *= np.exp(-alpha)\n",
    "\n",
    "        w /= w.sum()\n",
    "\n",
    "        models.append((alpha, clf))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, models):\n",
    "    \n",
    "    n_classes = 3\n",
    "    n_objects = len(X)\n",
    "    \n",
    "    y_pred = np.zeros((n_objects, n_classes))\n",
    "    \n",
    "    for alpha, clf in models:\n",
    "        prediction = clf.predict(X)\n",
    "        y_pred[range(n_objects), prediction] += alpha\n",
    "    \n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "\n",
    "models = adaboost(X_train, y_train, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала отмасштабируем выборку\n",
    "X_ = X_train.astype(float)\n",
    "\n",
    "rows, cols = X_.shape\n",
    "\n",
    "# центрирование - вычитание из каждого значения среднего по строке\n",
    "means = X_.mean(0)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        X_[i, j] -= means[j]\n",
    "\n",
    "# деление каждого значения на стандартное отклонение\n",
    "std = np.std(X_, axis=0)\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        X_[j][i] /= std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица весов W:\n",
      " [[-0.1017576   0.48681992]\n",
      " [ 0.2480939   0.22964871]\n",
      " [ 0.00680322  0.35592092]\n",
      " [ 0.23862015 -0.00568027]\n",
      " [-0.11463709  0.33557152]\n",
      " [-0.3914133   0.07898993]\n",
      " [-0.42378901  0.03598345]\n",
      " [ 0.28759444  0.02028919]\n",
      " [-0.3084663   0.02078229]\n",
      " [ 0.14324402  0.48304911]\n",
      " [-0.32503975 -0.21491215]\n",
      " [-0.39047192 -0.11659715]\n",
      " [-0.26204152  0.41164461]]\n"
     ]
    }
   ],
   "source": [
    "# Найдем собственные векторы и собственные значения\n",
    " \n",
    "covariance_matrix = X_.T.dot(X_)\n",
    "\n",
    "eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "# сформируем список кортежей (собственное значение, собственный вектор)\n",
    "eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "\n",
    "# и отсортируем список по убыванию собственных значений\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Сформируем вектор весов из собственных векторов, соответствующих первым двум главным компонентам\n",
    "W = np.hstack((eig_pairs[0][1].reshape(13,1), eig_pairs[1][1].reshape(13,1)))\n",
    "\n",
    "print(f'Матрица весов W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train=X_.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test=X_test[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# центрирование - вычитание из каждого значения среднего по строке\n",
    "for j in range(cols):\n",
    "    new_X_test[:, j] -= means[j]\n",
    "\n",
    "# деление каждого значения на стандартное отклонение\n",
    "for i in range(cols):\n",
    "    new_X_test[:, i] /= std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test=new_X_test.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, y):\n",
    "    return (sum(pred == y) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50 \n",
    "\n",
    "models = adaboost(new_X_train, y_train, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность алгоритма на обучающей выборке: 96.992\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность алгоритма на обучающей выборке: {(1 - get_error(predict(new_X_train, models), y_train)) * 100:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность алгоритма на тестовой выборке: 88.889\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность алгоритма на тестовой выборке: {(1 - get_error(predict(new_X_test, models), y_test)) * 100:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
